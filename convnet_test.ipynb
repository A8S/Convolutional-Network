{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1720, 2584) <type 'numpy.ndarray'>\n",
      "(43, 64)\n"
     ]
    }
   ],
   "source": [
    "im = scipy.ndimage.imread('cat.jpg', flatten=True)\n",
    "print im.shape, type(im)\n",
    "a = im.shape[0]\n",
    "b= im.shape[1]\n",
    "cat = scipy.misc.imresize(im, (a/40,b/40), interp='bilinear', mode=None)\n",
    "cat = 1.0 - cat/255.0\n",
    "print cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = np.empty((12*12))\n",
    "for i in range(144):\n",
    "    test[i] = i\n",
    "test = test.reshape((3,12,4))\n",
    "# print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEPTH = 3\n",
    "STRIDE = 1\n",
    "# to ensure that the input and output volumes are the same: use P=(F-1)/2 given stride 1.\n",
    "PADDING = 0\n",
    "FILTER_SIZE = 2\n",
    "\n",
    "class ToyNet(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        # initialize a list of filters\n",
    "        self.weights = []\n",
    "        for i in range(DEPTH):\n",
    "            self.weights.append([np.random.randn(FILTER_SIZE, FILTER_SIZE)])\n",
    "        self.biases = np.random.rand(DEPTH,1)\n",
    "        self.activations = []\n",
    "\n",
    "    def convolve(self, input_neurons):\n",
    "        '''\n",
    "        Assume input image to be of channel one!\n",
    "        '''\n",
    "        output_dim1 = (input_neurons.shape[0] - FILTER_SIZE + 2*PADDING)/STRIDE + 1        # num of rows\n",
    "        output_dim2 =  (input_neurons.shape[1] - FILTER_SIZE + 2*PADDING)/STRIDE + 1       # num of cols\n",
    "\n",
    "        for i in range(DEPTH):\n",
    "            self.activations.append(np.empty((output_dim1 * output_dim2)))\n",
    "\n",
    "        print 'shape of input (rows,cols): ', input_neurons.shape\n",
    "        print 'shape of output (rows, cols): ','(', output_dim1,',', output_dim2, ')'\n",
    "\n",
    "        for j in range(DEPTH):\n",
    "            slide = 0\n",
    "            row = 0\n",
    "            print self.activations[j].shape[0]    # one dimensional\n",
    "\n",
    "            for i in range(self.activations[j].shape[0]):  # loop til the output array is filled up -> one dimensional (600)\n",
    "\n",
    "                # ACTIVATIONS -> loop through each 2x2 block horizontally\n",
    "                self.activations[j][i] = sigmoid(np.sum(input_neurons[row:FILTER_SIZE+row, slide:FILTER_SIZE + slide] * self.weights[j][0]) + self.biases[j])\n",
    "                slide += STRIDE\n",
    "\n",
    "                if (FILTER_SIZE + slide)-STRIDE >= input_neurons.shape[1]:    # wrap indeces at the end of each row\n",
    "                    slide = 0\n",
    "                    row += STRIDE\n",
    "\n",
    "            self.activations[j] = self.activations[j].reshape((output_dim1, output_dim2))\n",
    "#         print self.activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PoolingLayer(object):\n",
    "\n",
    "    def __init__(self, width_in, height_in, depth, poolsize = (2,2)):\n",
    "        '''\n",
    "        width_in and height_in are the dimensions of the input image\n",
    "        poolsize is treated as a tuple of filter and stride -> it should work with overlapping pooling\n",
    "        '''\n",
    "        self.width_in = width_in\n",
    "        self.height_in = height_in\n",
    "        self.depth = depth\n",
    "        self.poolsize = poolsize\n",
    "        self.width_out = (self.width_in - self.poolsize[0])/self.poolsize[1] + 1      # num of output neurons\n",
    "        self.height_out = (self.height_in - self.poolsize[0])/self.poolsize[1] + 1\n",
    "        print self.height_out, self.width_out\n",
    "\n",
    "        # initialize empty output matrix\n",
    "        self.output = np.empty((self.depth, self.width_out * self.height_out))\n",
    "        self.max_indeces = np.empty((self.depth, self.width_out * self.height_out, 2))\n",
    "        print 'Shape of pooling layer: ', self.output.shape\n",
    "\n",
    "    def pool(self, input_image):\n",
    "        k = 0\n",
    "        \n",
    "        # for each filter map\n",
    "        for j in range(self.depth):\n",
    "            row = 0\n",
    "            slide = 0\n",
    "            for i in range(self.width_out * self.height_out):\n",
    "                toPool = input_image[j][row:self.poolsize[0] + row, slide:self.poolsize[0] + slide]\n",
    "\n",
    "                self.output[j][k] = np.amax(toPool)                # calculate the max activation\n",
    "                index = zip(*np.where(np.max(toPool) == toPool))           # save the index of the max\n",
    "                if len(index) > 1:\n",
    "                    index = [index[0]]\n",
    "                index = index[0][0]+ row, index[0][1] + slide\n",
    "                self.max_indeces[j][k] = index\n",
    "\n",
    "                slide += self.poolsize[1]\n",
    "\n",
    "                # modify this if stride != filter for poolsize \n",
    "                if slide >= self.width_in:\n",
    "                    slide = 0\n",
    "                    row += self.poolsize[1]\n",
    "                k += 1\n",
    "#                 print 'matrix: ', toPool,'max', self.output[j][k-1]\n",
    "#                 print 'index: ', self.max_indeces[j][k-1]\n",
    "#                 if k > 10:\n",
    "#                     break\n",
    "                \n",
    "        self.output = self.output.reshape((self.depth, self.height_out, self.width_out))\n",
    "        self.max_indeces = self.max_indeces.reshape((self.depth, self.height_out, self.width_out, 2))\n",
    "#         print 'AFTER RESHPAING:', self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class FullyConnectedLayer(object):\n",
    "\n",
    "#     def __init__(self, width_in, height_in, depth, num_neurons, num_classes):\n",
    "#         self.width_in = width_in\n",
    "#         self.height_in = height_in\n",
    "#         self.depth = depth                \n",
    "#         self.num_neurons = num_neurons\n",
    "#         self.num_classes = num_classes\n",
    "                \n",
    "#         self.weights = np.random.randn(self.num_neurons, self.depth, self.width_in, self.height_in)\n",
    "#         self.biases = np.random.randn(self.num_neurons)\n",
    "        \n",
    "#         self.output = np.empty((num_neurons, 1))\n",
    "\n",
    "#     def feedforward(self, a):\n",
    "#         print len(zip(self.biases, self.weights))\n",
    "#         i = 0\n",
    "#         for w,b in zip(self.weights, self.biases):     # num of iterations should be == num of num_neurons\n",
    "#             # TODO\n",
    "#             # take dot product from all neurons over full depth and convert into single neuron on FC layer\n",
    "#             print i, w.shape, a.shape\n",
    "#             i += 1\n",
    "#             print (np.inner(w, a) + b).shape\n",
    "#         return self.output\n",
    "    \n",
    "#     def classify(self):\n",
    "#         pass\n",
    "#         # I. initialize weights and biases!\n",
    "#         # II. forward prop\n",
    "#         # III. Calculate loss\n",
    "#         # Gradient descent -> backprop + update\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "\n",
    "    def __init__(self, width_in, height_in, depth, num_classes):\n",
    "        self.width_in = width_in\n",
    "        self.height_in = height_in\n",
    "        self.depth = depth                \n",
    "        self.num_neurons = self.width_in * self.height_in\n",
    "        self.num_classes = num_classes\n",
    "                \n",
    "        self.weights = np.random.randn(self.num_neurons, self.depth, self.width_in, self.height_in)\n",
    "        self.biases = np.random.randn(self.num_neurons)\n",
    "        \n",
    "        self.output = np.empty((self.width_in, self.height_in))\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        print len(zip(self.biases, self.weights))\n",
    "#         for w,b in zip(self.weights, self.biases):     # num of iterations should be == num of num_neurons\n",
    "        # TODO\n",
    "        # take dot product from all neurons over full depth and convert into single neuron on FC layer\n",
    "        # for each output neuron -> matrix mul: weight matrix over filters x input image + b\n",
    "        for j in range(self.width_in):\n",
    "            for i in range(self.height_in):\n",
    "                print a\n",
    "                print a[:][0]\n",
    "                break\n",
    "            break\n",
    "                \n",
    "            \n",
    "            \n",
    "#             print i, w.shape, a.shape\n",
    "#             i += 1\n",
    "#             print (np.inner(w, a) + b).shape\n",
    "#         return self.output\n",
    "    \n",
    "    def classify(self):\n",
    "        pass\n",
    "        # I. initialize weights and biases!\n",
    "        # II. forward prop\n",
    "        # III. Calculate loss\n",
    "        # Gradient descent -> backprop + update\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net = ToyNet([test.shape[0]*test.shape[1]])\n",
    "# print 'yooooo', net.sizes[0]\n",
    "# net.convolve(test)\n",
    "\n",
    "# TODO: implement for all activations!\n",
    "# pool_layer = PoolingLayer(12, 12, 1) # only implemented for the first depth layer\n",
    "# pool_layer.pool(test)\n",
    "fc = FullyConnectedLayer(3,12,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]]\n"
     ]
    }
   ],
   "source": [
    "test = np.empty((12*12))\n",
    "for i in range(144):\n",
    "    test[i] = i\n",
    "test = test.reshape((3,12,4))\n",
    "# print test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
